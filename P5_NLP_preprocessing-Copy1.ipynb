{
 "cells": [
  {
   "attachments": {
    "t%C3%A9l%C3%A9chargement.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t%C3%A9l%C3%A9chargement.png](attachment:t%C3%A9l%C3%A9chargement.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compréhension des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\perso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\perso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import gc\n",
    "from langdetect import detect\n",
    "\n",
    "# Download the required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"QueryResults.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Making a particle follow a path in spriteKit</td>\n",
       "      <td>&lt;p&gt;I have created a particle and when I test i...</td>\n",
       "      <td>&lt;ios&gt;&lt;iphone&gt;&lt;ipad&gt;&lt;sprite-kit&gt;&lt;skemitternode&gt;</td>\n",
       "      <td>18986098</td>\n",
       "      <td>17</td>\n",
       "      <td>6492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to find the cause of a malloc \"double free...</td>\n",
       "      <td>&lt;p&gt;I'm programming an application in Objective...</td>\n",
       "      <td>&lt;iphone&gt;&lt;objective-c&gt;&lt;memory-management&gt;&lt;mallo...</td>\n",
       "      <td>971249</td>\n",
       "      <td>82</td>\n",
       "      <td>79057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Handling the window closing event with WPF / M...</td>\n",
       "      <td>&lt;p&gt;I'd like to handle the &lt;code&gt;Closing&lt;/code&gt;...</td>\n",
       "      <td>&lt;c#&gt;&lt;wpf&gt;&lt;xaml&gt;&lt;mvvm&gt;&lt;mvvm-light&gt;</td>\n",
       "      <td>3683450</td>\n",
       "      <td>157</td>\n",
       "      <td>231366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SessionTimeout: web.xml vs session.maxInactive...</td>\n",
       "      <td>&lt;p&gt;I'm trying to timeout an &lt;em&gt;HttpSession&lt;/e...</td>\n",
       "      <td>&lt;java&gt;&lt;session&gt;&lt;servlets&gt;&lt;weblogic&gt;&lt;session-ti...</td>\n",
       "      <td>3118968</td>\n",
       "      <td>65</td>\n",
       "      <td>113655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting GDB to save a list of breakpoints</td>\n",
       "      <td>&lt;p&gt;OK, &lt;em&gt;&lt;a href=\"https://sourceware.org/gdb...</td>\n",
       "      <td>&lt;c++&gt;&lt;c&gt;&lt;debugging&gt;&lt;gdb&gt;&lt;breakpoints&gt;</td>\n",
       "      <td>501486</td>\n",
       "      <td>146</td>\n",
       "      <td>51459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0       Making a particle follow a path in spriteKit   \n",
       "1  How to find the cause of a malloc \"double free...   \n",
       "2  Handling the window closing event with WPF / M...   \n",
       "3  SessionTimeout: web.xml vs session.maxInactive...   \n",
       "4          Getting GDB to save a list of breakpoints   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I have created a particle and when I test i...   \n",
       "1  <p>I'm programming an application in Objective...   \n",
       "2  <p>I'd like to handle the <code>Closing</code>...   \n",
       "3  <p>I'm trying to timeout an <em>HttpSession</e...   \n",
       "4  <p>OK, <em><a href=\"https://sourceware.org/gdb...   \n",
       "\n",
       "                                                Tags        Id  Score  \\\n",
       "0     <ios><iphone><ipad><sprite-kit><skemitternode>  18986098     17   \n",
       "1  <iphone><objective-c><memory-management><mallo...    971249     82   \n",
       "2                  <c#><wpf><xaml><mvvm><mvvm-light>   3683450    157   \n",
       "3  <java><session><servlets><weblogic><session-ti...   3118968     65   \n",
       "4              <c++><c><debugging><gdb><breakpoints>    501486    146   \n",
       "\n",
       "   ViewCount  FavoriteCount  AnswerCount  \n",
       "0       6492            0.0            1  \n",
       "1      79057            0.0           13  \n",
       "2     231366            0.0           14  \n",
       "3     113655            0.0            2  \n",
       "4      51459            0.0           11  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Title          50000 non-null  object \n",
      " 1   Body           50000 non-null  object \n",
      " 2   Tags           50000 non-null  object \n",
      " 3   Id             50000 non-null  int64  \n",
      " 4   Score          50000 non-null  int64  \n",
      " 5   ViewCount      50000 non-null  int64  \n",
      " 6   FavoriteCount  43480 non-null  float64\n",
      " 7   AnswerCount    50000 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            50000\n",
       "Body             50000\n",
       "Tags             49090\n",
       "Id               50000\n",
       "Score              737\n",
       "ViewCount        27428\n",
       "FavoriteCount        3\n",
       "AnswerCount         65\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Making a particle follow a path in spriteKit</td>\n",
       "      <td>&lt;p&gt;I have created a particle and when I test i...</td>\n",
       "      <td>&lt;ios&gt;&lt;iphone&gt;&lt;ipad&gt;&lt;sprite-kit&gt;&lt;skemitternode&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to find the cause of a malloc \"double free...</td>\n",
       "      <td>&lt;p&gt;I'm programming an application in Objective...</td>\n",
       "      <td>&lt;iphone&gt;&lt;objective-c&gt;&lt;memory-management&gt;&lt;mallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Handling the window closing event with WPF / M...</td>\n",
       "      <td>&lt;p&gt;I'd like to handle the &lt;code&gt;Closing&lt;/code&gt;...</td>\n",
       "      <td>&lt;c#&gt;&lt;wpf&gt;&lt;xaml&gt;&lt;mvvm&gt;&lt;mvvm-light&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SessionTimeout: web.xml vs session.maxInactive...</td>\n",
       "      <td>&lt;p&gt;I'm trying to timeout an &lt;em&gt;HttpSession&lt;/e...</td>\n",
       "      <td>&lt;java&gt;&lt;session&gt;&lt;servlets&gt;&lt;weblogic&gt;&lt;session-ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting GDB to save a list of breakpoints</td>\n",
       "      <td>&lt;p&gt;OK, &lt;em&gt;&lt;a href=\"https://sourceware.org/gdb...</td>\n",
       "      <td>&lt;c++&gt;&lt;c&gt;&lt;debugging&gt;&lt;gdb&gt;&lt;breakpoints&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0       Making a particle follow a path in spriteKit   \n",
       "1  How to find the cause of a malloc \"double free...   \n",
       "2  Handling the window closing event with WPF / M...   \n",
       "3  SessionTimeout: web.xml vs session.maxInactive...   \n",
       "4          Getting GDB to save a list of breakpoints   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I have created a particle and when I test i...   \n",
       "1  <p>I'm programming an application in Objective...   \n",
       "2  <p>I'd like to handle the <code>Closing</code>...   \n",
       "3  <p>I'm trying to timeout an <em>HttpSession</e...   \n",
       "4  <p>OK, <em><a href=\"https://sourceware.org/gdb...   \n",
       "\n",
       "                                                Tags  \n",
       "0     <ios><iphone><ipad><sprite-kit><skemitternode>  \n",
       "1  <iphone><objective-c><memory-management><mallo...  \n",
       "2                  <c#><wpf><xaml><mvvm><mvvm-light>  \n",
       "3  <java><session><servlets><weblogic><session-ti...  \n",
       "4              <c++><c><debugging><gdb><breakpoints>  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Title', 'Body', 'Tags']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title    0\n",
       "Body     0\n",
       "Tags     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Title   50000 non-null  object\n",
      " 1   Body    50000 non-null  object\n",
      " 2   Tags    50000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML tags from Body column\n",
    "data['Body_clean'] = data['Body'].apply(lambda x: re.sub('<.*?>', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Body_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Making a particle follow a path in spriteKit</td>\n",
       "      <td>&lt;p&gt;I have created a particle and when I test i...</td>\n",
       "      <td>&lt;ios&gt;&lt;iphone&gt;&lt;ipad&gt;&lt;sprite-kit&gt;&lt;skemitternode&gt;</td>\n",
       "      <td>I have created a particle and when I test it m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to find the cause of a malloc \"double free...</td>\n",
       "      <td>&lt;p&gt;I'm programming an application in Objective...</td>\n",
       "      <td>&lt;iphone&gt;&lt;objective-c&gt;&lt;memory-management&gt;&lt;mallo...</td>\n",
       "      <td>I'm programming an application in Objective-C ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Handling the window closing event with WPF / M...</td>\n",
       "      <td>&lt;p&gt;I'd like to handle the &lt;code&gt;Closing&lt;/code&gt;...</td>\n",
       "      <td>&lt;c#&gt;&lt;wpf&gt;&lt;xaml&gt;&lt;mvvm&gt;&lt;mvvm-light&gt;</td>\n",
       "      <td>I'd like to handle the Closing event (when a u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SessionTimeout: web.xml vs session.maxInactive...</td>\n",
       "      <td>&lt;p&gt;I'm trying to timeout an &lt;em&gt;HttpSession&lt;/e...</td>\n",
       "      <td>&lt;java&gt;&lt;session&gt;&lt;servlets&gt;&lt;weblogic&gt;&lt;session-ti...</td>\n",
       "      <td>I'm trying to timeout an HttpSession in Java. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting GDB to save a list of breakpoints</td>\n",
       "      <td>&lt;p&gt;OK, &lt;em&gt;&lt;a href=\"https://sourceware.org/gdb...</td>\n",
       "      <td>&lt;c++&gt;&lt;c&gt;&lt;debugging&gt;&lt;gdb&gt;&lt;breakpoints&gt;</td>\n",
       "      <td>OK, info break lists the breakpoints, but not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>How can I String.Format a TimeSpan object with...</td>\n",
       "      <td>&lt;p&gt;What is the recommended way of formatting &lt;...</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;&lt;string&gt;&lt;time&gt;&lt;formatting&gt;</td>\n",
       "      <td>What is the recommended way of formatting Time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>How can Polymorphism replace an if-else statem...</td>\n",
       "      <td>&lt;p&gt;How can polymorphism replace an if-else sta...</td>\n",
       "      <td>&lt;language-agnostic&gt;&lt;oop&gt;&lt;loops&gt;&lt;polymorphism&gt;&lt;...</td>\n",
       "      <td>How can polymorphism replace an if-else statem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>What thread does JavaScript code called from F...</td>\n",
       "      <td>&lt;p&gt;As far as I understand, all JavaScript code...</td>\n",
       "      <td>&lt;javascript&gt;&lt;flash&gt;&lt;actionscript-3&gt;&lt;multithrea...</td>\n",
       "      <td>As far as I understand, all JavaScript code is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Android Gradle's dependency cache may be corru...</td>\n",
       "      <td>&lt;p&gt;I am trying to import this project, even I ...</td>\n",
       "      <td>&lt;java&gt;&lt;android&gt;&lt;android-studio&gt;&lt;gradle&gt;&lt;build....</td>\n",
       "      <td>I am trying to import this project, even I tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Is there a way to read environment variables o...</td>\n",
       "      <td>&lt;p&gt;In Perl, I need to read the environment of ...</td>\n",
       "      <td>&lt;linux&gt;&lt;perl&gt;&lt;solaris&gt;&lt;environment-variables&gt;&lt;...</td>\n",
       "      <td>In Perl, I need to read the environment of oth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "0           Making a particle follow a path in spriteKit   \n",
       "1      How to find the cause of a malloc \"double free...   \n",
       "2      Handling the window closing event with WPF / M...   \n",
       "3      SessionTimeout: web.xml vs session.maxInactive...   \n",
       "4              Getting GDB to save a list of breakpoints   \n",
       "...                                                  ...   \n",
       "49995  How can I String.Format a TimeSpan object with...   \n",
       "49996  How can Polymorphism replace an if-else statem...   \n",
       "49997  What thread does JavaScript code called from F...   \n",
       "49998  Android Gradle's dependency cache may be corru...   \n",
       "49999  Is there a way to read environment variables o...   \n",
       "\n",
       "                                                    Body  \\\n",
       "0      <p>I have created a particle and when I test i...   \n",
       "1      <p>I'm programming an application in Objective...   \n",
       "2      <p>I'd like to handle the <code>Closing</code>...   \n",
       "3      <p>I'm trying to timeout an <em>HttpSession</e...   \n",
       "4      <p>OK, <em><a href=\"https://sourceware.org/gdb...   \n",
       "...                                                  ...   \n",
       "49995  <p>What is the recommended way of formatting <...   \n",
       "49996  <p>How can polymorphism replace an if-else sta...   \n",
       "49997  <p>As far as I understand, all JavaScript code...   \n",
       "49998  <p>I am trying to import this project, even I ...   \n",
       "49999  <p>In Perl, I need to read the environment of ...   \n",
       "\n",
       "                                                    Tags  \\\n",
       "0         <ios><iphone><ipad><sprite-kit><skemitternode>   \n",
       "1      <iphone><objective-c><memory-management><mallo...   \n",
       "2                      <c#><wpf><xaml><mvvm><mvvm-light>   \n",
       "3      <java><session><servlets><weblogic><session-ti...   \n",
       "4                  <c++><c><debugging><gdb><breakpoints>   \n",
       "...                                                  ...   \n",
       "49995               <c#><.net><string><time><formatting>   \n",
       "49996  <language-agnostic><oop><loops><polymorphism><...   \n",
       "49997  <javascript><flash><actionscript-3><multithrea...   \n",
       "49998  <java><android><android-studio><gradle><build....   \n",
       "49999  <linux><perl><solaris><environment-variables><...   \n",
       "\n",
       "                                              Body_clean  \n",
       "0      I have created a particle and when I test it m...  \n",
       "1      I'm programming an application in Objective-C ...  \n",
       "2      I'd like to handle the Closing event (when a u...  \n",
       "3      I'm trying to timeout an HttpSession in Java. ...  \n",
       "4      OK, info break lists the breakpoints, but not ...  \n",
       "...                                                  ...  \n",
       "49995  What is the recommended way of formatting Time...  \n",
       "49996  How can polymorphism replace an if-else statem...  \n",
       "49997  As far as I understand, all JavaScript code is...  \n",
       "49998  I am trying to import this project, even I tri...  \n",
       "49999  In Perl, I need to read the environment of oth...  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove punctuations and digits\n",
    "def remove_punc_digits(text):\n",
    "    # Remove digits\n",
    "    text = re.sub('\\d+', '', text)\n",
    "    text = text.lower()\n",
    "    # Remove punctuations and special characters\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to Title and Body columns\n",
    "data['Title_clean'] = data['Title'].apply(remove_punc_digits)\n",
    "data['Body_clean'] = data['Body_clean'].apply(remove_punc_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\perso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1ccd6e1bf5b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Tokenize the texts and convert to lowercase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Count the frequency of each word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-1ccd6e1bf5b0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Tokenize the texts and convert to lowercase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Count the frequency of each word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     return [\n\u001b[0;32m    132\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m    107\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1272\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m         \"\"\"\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m         \"\"\"\n\u001b[1;32m-> 1328\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m         \"\"\"\n\u001b[1;32m-> 1328\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1318\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1319\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1357\u001b[0m         \"\"\"\n\u001b[0;32m   1358\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1341\u001b[0m                     \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[1;31m# The last sentence should not contain trailing whitespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1343\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List of texts to analyze\n",
    "texts = data['Body_clean']\n",
    "\n",
    "# Tokenize the texts and convert to lowercase\n",
    "words = [word.lower() for text in texts for word in nltk.word_tokenize(text)]\n",
    "\n",
    "# Count the frequency of each word\n",
    "freq = Counter(words)\n",
    "\n",
    "# Get the most common 200 words and combine with default NLTK stopwords\n",
    "most_freq = [word for word, count in freq.most_common(100)]\n",
    "sw = set(stopwords.words('english')).union(set(most_freq))\n",
    "\n",
    "# Remove stopwords from the list of words\n",
    "words_without_sw = [word for word in words if word not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Tokenize le texte\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Enlève les stopwords\n",
    "    stopwords_en = set(stopwords.words('english'))\n",
    "    tokens_without_sw = [token for token in tokens if token not in stopwords_en]\n",
    "    # Retourne la liste de mots sans stopwords\n",
    "    return tokens_without_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applique la fonction de nettoyage à la colonne \"Body\"\n",
    "data['Body_clean'] = data['Body_clean'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of texts to analyze\n",
    "texts = data['Title_clean']\n",
    "\n",
    "# Tokenize the texts and convert to lowercase\n",
    "words = [word.lower() for text in texts for word in nltk.word_tokenize(text)]\n",
    "\n",
    "# Count the frequency of each word\n",
    "freq = Counter(words)\n",
    "\n",
    "# Get the most common 100 words and combine with default NLTK stopwords\n",
    "most_freq = [word for word, count in freq.most_common(100)]\n",
    "sw = set(stopwords.words('english')).union(set(most_freq))\n",
    "\n",
    "# Remove stopwords from the list of words\n",
    "words_without_sw = [word for word in words if word not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applique la fonction de nettoyage à la colonne \"Body\"\n",
    "data['Title_clean'] = data['Title_clean'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion des Titles & Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Texte_clean'] = data['Title_clean'] + data['Body_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Texte_clean'] = data['Texte_clean'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre Langue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in data.index:\n",
    "    data.loc[index,'lang'] = detect(data.loc[index,'Texte_clean']) \n",
    "\n",
    "data['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtre Anglais\n",
    "data = data[data['lang']=='en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pos tag\n",
    "POS Tagging (Part-of-Speech Tagging) : représente les méthodes qui récupèrent la nature grammatical des mots d’une phrase - nom, verbe, adjectif, etc. Ce sont des propriété qui peuvent servir de caractéristiques utile lors de la création de certains modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_verbs(text):\n",
    "\n",
    "    # tokenisation des mots\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # obtention du type grammatical de chaque mot\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "    filtered_tokens = [word for word, tag in tagged_tokens if tag not in [\n",
    "        'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',  # verbs\n",
    "        'PRP', 'PRP$',  # pronouns\n",
    "        'DT', 'PDT', 'WDT',  # determiners\n",
    "        'MD'  # modals/auxiliaries\n",
    "    ]]\n",
    "\n",
    "    # lemmatisation des mots restants\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(\n",
    "        token, pos='v') for token in filtered_tokens]\n",
    "\n",
    "    # sélection des mots non verbaux\n",
    "    non_verbs = [token for token in lemmatized_tokens if not wn.synsets(\n",
    "        token, pos=wn.VERB)]\n",
    "\n",
    "    # reconstruction du texte sans verbes\n",
    "    cleaned_text = ' '.join(non_verbs)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Texte_clean'] = data['Texte_clean'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applique la fonction de nettoyage à la colonne \"Body\"\n",
    "data['Texte_remove'] = data['Texte_clean'].apply(remove_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Texte_remove'] = data['Texte_remove'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer tous les caractères dans la colonne \"Text_lem\"\n",
    "data['Texte_remove'] = data['Texte_remove'].str.replace(\"[\", \"\")\n",
    "data['Texte_remove'] = data['Texte_remove'].str.replace(\"]\", \"\")\n",
    "data['Texte_remove'] = data['Texte_remove'].str.replace(\"'\", \"\")\n",
    "data['Texte_remove'] = data['Texte_remove'].str.replace('\"', '')\n",
    "data['Texte_remove'] = data['Texte_remove'].str.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacer tous les caractères dans la colonne \"Tags\"\n",
    "data['Tags_clean'] = data['Tags'].str.replace(\"<|>\",\" \")\n",
    "data['Tags_clean'] = data['Tags_clean'].str.replace(\",+\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tags_clean'] = data['Tags_clean'].apply(remove_punc_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Feature prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Title', 'Body', 'Tags', 'Body_clean',\n",
    "          'Title_clean', 'Texte_clean','lang'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated(subset='Texte_remove').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    n = data.duplicated(subset=col).sum()\n",
    "    print(f\"col: {col} -> duplicated : {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser la distribution des longueurs de texte\n",
    "text_lengths = data['Tags_clean'].str.len()\n",
    "plt.hist(text_lengths, bins=50)\n",
    "plt.xlabel('Longueur du texte')\n",
    "plt.ylabel('Nombre d\\'observations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(width = 800, \n",
    "                height = 1000,\n",
    "                background_color ='white',\n",
    "                max_words = 1000, \n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 12,\n",
    "                colormap=\"Set2\"\n",
    "                ).generate(str(data[\"Tags_clean\"]))\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tags_split'] = data.apply(lambda r :r['Tags_clean'].split(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liste_tags(document) :\n",
    "    dico_tags = {}\n",
    "    for sentence in document :\n",
    "        for tag in sentence :\n",
    "            if tag in dico_tags :\n",
    "                dico_tags[tag] += 1\n",
    "            else :\n",
    "                dico_tags[tag] = 1\n",
    "    return dico_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_tags = liste_tags(data['Tags_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.DataFrame(list(dico_tags.items()), columns = ['Tags', 'Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier la feature par ordre décroissant\n",
    "tags_df.sort_values(by='Quantity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'Quantity'\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(15,5)})\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "sns.histplot(tags_df, x=var, bins=30, ax=ax1)\n",
    "sns.boxplot(tags_df[var], ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counting_graph = tags_df.sort_values(['Quantity'], ascending=False)\n",
    "plt.plot(tags_counting_graph['Quantity'].values)\n",
    "plt.grid(True)\n",
    "plt.title(\"Distribution des tags :\")\n",
    "plt.xlabel(\"Nombre de tags les plus fréquents\")\n",
    "plt.ylabel(\"Fréquence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tags_counting_graph['Quantity'][0:100].values)\n",
    "plt.grid(True)\n",
    "plt.title(\"Distribution des top 100 tags :\")\n",
    "plt.xlabel(\"Nombre de tags les plus fréquents\")\n",
    "plt.ylabel(\"Fréquence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tags_counting_graph['Quantity'][0:10].values)\n",
    "plt.grid(True)\n",
    "plt.title(\"Distribution des top 10 tags :\")\n",
    "plt.xlabel(\"Nombre de tags les plus fréquents\")\n",
    "plt.ylabel(\"Fréquence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} tags qui sont utilisés plus de 10 fois\".format(tags_df[tags_df[\"Quantity\"]>10].shape[0]))\n",
    "print(\"{} tags qui sont utilisés plus de 25 fois\".format(tags_df[tags_df[\"Quantity\"]>25].shape[0]))\n",
    "print(\"{} tags qui sont utilisés plus de 50 fois\".format(tags_df[tags_df[\"Quantity\"]>50].shape[0]))\n",
    "print(\"{} tags qui sont utilisés plus de 100 fois\".format(tags_df[tags_df[\"Quantity\"]>100].shape[0]))\n",
    "print(\"{} tags qui sont utilisés plus de 200 fois\".format(tags_df[tags_df[\"Quantity\"]>200].shape[0]))\n",
    "print(\"{} tags qui sont utilisés plus de 500 fois\".format(tags_df[tags_df[\"Quantity\"]>500].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtre des tags avec le plus de quantité\n",
    "tags_df = tags_df[tags_df['Quantity'] >200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_importante = tags_df['Tags'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tags(tags):\n",
    "    tags_list = tags.split()\n",
    "    # filtre les tags en gardant uniquement ceux qui sont importants\n",
    "    filtered_tags = [tag for tag in tags_list if tag in tags_importante]\n",
    "    if len(filtered_tags) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        # retourne une tuple contenant les tags filtrés et leur longueur\n",
    "        return ' '.join(filtered_tags), len(filtered_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la fonction\n",
    "data[['Tags_filtered', 'Tags_filtered_len']] = data['Tags_clean'].apply(\n",
    "    lambda x: filter_tags(x)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['Tags_filtered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(width = 800, height = 1000,\n",
    "                max_words=1000,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 12,\n",
    "                colormap=\"Set2\").generate(str(data[\"Tags_filtered\"]))\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop features Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Tags_clean', 'Tags_split'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser la distribution des longueurs de texte\n",
    "text_lengths = data['Texte_remove'].str.len()\n",
    "plt.hist(text_lengths, bins=50)\n",
    "plt.xlabel('Longueur du texte')\n",
    "plt.ylabel('Nombre d\\'observations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(width = 800, height = 1000,\n",
    "                max_words=1000,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 12,\n",
    "                colormap=\"Set2\").generate(str(data[\"Texte_remove\"]))\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text_split'] = data.apply(lambda r :r['Texte_remove'].split(), axis=1)\n",
    "filtered_text = data['Text_split'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_distribution(corpus):\n",
    "    from nltk import FreqDist\n",
    "    word_corpus = [token for token_list in corpus for token in token_list]\n",
    "    word_dist = FreqDist(word_corpus)\n",
    "    word_dist_df = pd.DataFrame(word_dist.items(), columns=['Words', 'Frequency'])\n",
    "    word_dist_df.sort_values(\"Frequency\", ascending=False, inplace=True)\n",
    "    return word_dist_df\n",
    "\n",
    "words_df = build_word_distribution(filtered_text)\n",
    "print(f\"Nombre de tokens du corpus {words_df.shape[0]}\")\n",
    "print(\"Affichage des 60 tokens les plus utilisés\")\n",
    "display(words_df.head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'Frequency'\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(15,5)})\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "sns.histplot(words_df, x=var, bins=30, ax=ax1)\n",
    "sns.boxplot(words_df[var], ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_counting_graph = words_df.sort_values(['Frequency'], ascending=False)\n",
    "plt.plot(words_counting_graph['Frequency'].values)\n",
    "plt.grid(True)\n",
    "plt.title(\"Distribution des mots du corpus :\")\n",
    "plt.xlabel(\"Nombre de mots les plus fréquents\")\n",
    "plt.ylabel(\"Fréquence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(words_counting_graph['Frequency'][0:100].values)\n",
    "plt.grid(True)\n",
    "plt.title(\"Distribution des top 100 mots :\")\n",
    "plt.xlabel(\"Nombre de mots les plus fréquents\")\n",
    "plt.ylabel(\"Fréquence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(words_counting_graph['Frequency'][0:10].values)\n",
    "plt.grid(True)\n",
    "plt.title(\"Distribution des top 10 mots :\")\n",
    "plt.xlabel(\"Nombre de mots les plus fréquents\")\n",
    "plt.ylabel(\"Fréquence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} mots qui sont utilisés plus de 10 fois\".format(words_df[words_df['Frequency']>10].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 25 fois\".format(words_df[words_df['Frequency']>25].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 50 fois\".format(words_df[words_df['Frequency']>50].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 100 fois\".format(words_df[words_df['Frequency']>100].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 200 fois\".format(words_df[words_df['Frequency']>200].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 500 fois\".format(words_df[words_df['Frequency']>500].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 1000 fois\".format(words_df[words_df['Frequency']>1000].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 5000 fois\".format(words_df[words_df['Frequency']>5000].shape[0]))\n",
    "print(\"{} mots qui sont utilisés plus de 50000 fois\".format(words_df[words_df['Frequency']>50000].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionnaire d'exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtre des mots avec le plus de quantité + garder les tags importante\n",
    "words_df = words_df[words_df['Tag'].isin(tags_importante) & (words_df['Frequency'] > 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_importante = words_df['Words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(words):\n",
    "    filtered_words = list(filter(lambda w: w in words_importante, words))\n",
    "    if len(filtered_words) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        # retourne les words filtrés et leur longueur\n",
    "        return ' '.join(filtered_words), len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la fonction\n",
    "data[['Words_filtered', 'Words_filtered_len']] = data['Text_split'].apply(\n",
    "    lambda x: filter_words(x)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['Words_filtered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(width = 800, height = 1000,\n",
    "                max_words=1000,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 12,\n",
    "                colormap=\"Set2\").generate(str(data[\"Words_filtered\"]))\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop features words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Texte_remove','Text_split'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_fct(sentence) :\n",
    "    return len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Texte_len\"] = data['Words_filtered'].apply(len_fct)\n",
    "data[\"Texte_len\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data[\"Texte_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Texte_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tags_len\"] = data[\"Tags_filtered\"].apply(len_fct)\n",
    "data[\"Tags_len\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data[\"Tags_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Texte_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tags_len_ratio\"] = round(data.apply(\n",
    "    lambda r: (r[\"Texte_len\"] / r[\"Tags_len\"]), axis=1))\n",
    "data[\"Tags_len_ratio\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data[\"Tags_len_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data[\"Texte_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df[['Score', 'ViewCount',\n",
    "                'AnswerCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_feature,data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les total de data pour chaque feature et le pourcentage de missing value\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Score', 'ViewCount', 'AnswerCount', 'Texte_len','Tags_len','Tags_filtered_len','Words_filtered_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réprésentation avec un displot \n",
    "for col in cols:\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    sns.distplot(df[col], label=\"skew: \"+str(np.round(df[col].skew(),2)))\n",
    "    plt.title(col)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "        w, pvalue = st.shapiro(df[col])\n",
    "        seuil = 0.05\n",
    "        print(f'{col :-<50} {w} {pvalue}')\n",
    "        if pvalue > seuil:\n",
    "            print(\n",
    "                \"On ne peux pas rejetter H0: la distribution suit une loi normale\")\n",
    "        else:\n",
    "            print(\n",
    "                \"On rejette H0 : la distribution ne suit pas une loi normale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Application d'une transformation logarithmique sur nos données numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['Score', 'ViewCount', 'AnswerCount', 'Texte_len','Tags_len','Tags_filtered_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log(x+1) element-wise to a subset of columns\n",
    "df_transform = df_transform[cols_to_scale].applymap(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation avant / Après log transform\n",
    "for col1, col2 in zip(cols,cols_to_scale):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    sns.distplot(df[col1], ax=axes[0], label=\"skew: \"+str(np.round(df[col1].skew(),2)))\n",
    "    axes[0].set_title(f'{col1} Before Log transform')\n",
    "    sns.distplot(df_transform[col2], ax=axes[1], label=\"skew: \"+str(np.round(df_transform[col2].skew(),2)))\n",
    "    axes[1].set_title(f'{col2} After Log transform')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse multivariée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation coefficients\n",
    "corr_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the correlation matrix\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation matrix as a heatmap\n",
    "mask = np.zeros_like(corr_matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr_matrix, mask=mask, vmin=-1, vmax=1, cmap='coolwarm',\n",
    "            annot=True, fmt=\".2f\", square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot with hue score\n",
    "sns.pairplot(df, hue='Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('QueryResults_explored.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.966px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
